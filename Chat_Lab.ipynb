{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc96dc43-8bbf-4d82-9010-34b802ae4798",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build a Chatbot with Amazon Bedrock\n",
    "\n",
    "## Objective One: Develop an Interactive Python Chat Application Utilizing Amazon Bedrock\n",
    "\n",
    "In this notebook, we will  build a simple Chatbot that interacts with Amazon Bedrock, we'll use InMemoryChatMessageHistory to store the conversation history.\n",
    "1. Install the required dependencies to interact with Amazon Bedrock\n",
    "2. Configure parameters for the model to use\n",
    "3. Initialize the chat model \n",
    "4. Invoke Bedrock\n",
    "5. Perform a multi-turn conversation with the chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11733ca-cd49-4cb9-abe0-f7b519bb188a",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies to interact with Amazon Bedrock\n",
    "Install the required packages needed. Ignore any pip dependency errors, they won't affect what we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223cf8a-1da7-457f-850d-485690844880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -q botocore\n",
    "%pip install --upgrade -q boto3\n",
    "%pip install --upgrade -q awscli\n",
    "%pip install --upgrade -q langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7510d-39d6-4386-8b76-1bde72fdbedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e2e43-c77c-4c8e-a581-f43bfd89fe86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892226c-1117-461a-b72a-a5616c7a45ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws.chat_models import ChatBedrock\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80151c5c-d919-46d2-83d3-c52d0c550bf5",
   "metadata": {},
   "source": [
    "### Start a boto3 session\n",
    "Needed to handle the session and manage interaction with AWS APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0761cfa-a2c2-4d52-be5a-dddae776a9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_session = boto3.session.Session()\n",
    "region = boto3_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b7041-c816-4764-8672-4b7057e7e705",
   "metadata": {},
   "source": [
    "## 2. Configure parameters for the model to use\n",
    "Specify the foundation model, and we can also set up other parameters like temperature to control the level of creativity we want the model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb59de4-fcdf-4cfd-b243-2f16da715516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"amazon.titan-text-lite-v1\"\n",
    "temperature = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ec0fb-f50c-4fd2-9dd7-cd0aa44c11ff",
   "metadata": {},
   "source": [
    "## 3. Initialize the chat model \n",
    "Using the ChatBedrock class from LangChain, initialize a chat model that uses the Bedrock API. LangChain provides a framework to enable back and forth interactions between a user and model, combined with memory and using a chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28852f4f-d7e1-49a8-959b-1a8eb8e8083d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chat = ChatBedrock(\n",
    "    model_id=model, \n",
    "    model_kwargs={\"temperature\": temperature},\n",
    "    region_name=region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cdcab-ce24-4fb0-ba5f-cd4359690fdc",
   "metadata": {},
   "source": [
    "### Configure conversation history\n",
    "InMemoryChatMessageHistory stores messages in a memory list.\n",
    "RunnableWithMessageHistory is used to handle message history during the conversation, saving each conversation with a session_id. It uses the session_id to identify up the relevant conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18901bf2-b71f-4941-9a39-f53d05d0ae38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(llm_chat, \n",
    "                                                  get_session_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45a9d0-9f84-4146-bc8d-f466fc7b6252",
   "metadata": {},
   "source": [
    "## 4. Invoke Bedrock \n",
    "Using LangChain to invoke Bedrock, maintaining the conversation history for our session, and providing a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb8438-b0b0-42a3-aacd-53d1fa316d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Help me create a social post about 5 ways to stay productive\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134cbaca-b8cd-4c93-acfd-a8aa239eda7c",
   "metadata": {},
   "source": [
    "## 5. Perform a multi-turn conversation with the chatbot\n",
    "Continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60275cab-a8d8-470a-bfa3-8b78636d28d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Add one more tip that is completely different to the ones already provided\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c975f46-0e2a-4823-bdd9-be2a8ec9ce9d",
   "metadata": {},
   "source": [
    "### Print the stored conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45c386-dca0-4b9d-98fd-4df46e26b52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
